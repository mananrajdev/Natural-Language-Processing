{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Amazon Reviews - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary and Ternary Sentiment Analysis\n",
    "## Data generation -> Word Embedding -> Data Preprocessing -> TF-IDF -> Simple Model (Perceptron, SVM) -> Feedforward Neural Networks -> Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Summary of Accuracies is present at the end of the notebook along with some obervations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim import utils\n",
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    " data=pd.read_csv('amazon_reviews_us_Kitchen_v1_00.tsv', sep=\"\\t\", error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[[\"review_body\",\"star_rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "1.0     426870\n",
       "2.0     241939\n",
       "3.0     349539\n",
       "4.0     731701\n",
       "5.0    3124595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of all the reviews\n",
    "df=df.dropna()\n",
    "df_grouped = df.groupby('star_rating')\n",
    "df_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df.groupby('star_rating', group_keys=False).apply(lambda grp: grp.sample(n=50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "1.0    50000\n",
       "2.0    50000\n",
       "3.0    50000\n",
       "4.0    50000\n",
       "5.0    50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.groupby('star_rating').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled=df_subset.copy()\n",
    "df_labeled['star_rating'][(df_labeled['star_rating'] <= 2 )] = 0\n",
    "df_labeled['star_rating'][(df_labeled['star_rating'] > 3 )] = 1\n",
    "df_labeled['star_rating'][(df_labeled['star_rating'] == 3 )] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2854151</th>\n",
       "      <td>Exactly what I thought I was purchasing. I mea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413003</th>\n",
       "      <td>The Top keeps opening for a shaker bottle. Def...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779547</th>\n",
       "      <td>This has a bitter taste. It is no good.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715603</th>\n",
       "      <td>I haven't used this yet as I am waiting for my...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753248</th>\n",
       "      <td>Authentic shape. Used black and yellow sprinkl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "2854151  Exactly what I thought I was purchasing. I mea...          1.0\n",
       "2413003  The Top keeps opening for a shaker bottle. Def...          0.0\n",
       "4779547            This has a bitter taste. It is no good.          0.0\n",
       "2715603  I haven't used this yet as I am waiting for my...          2.0\n",
       "753248   Authentic shape. Used black and yellow sprinkl...          1.0"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "0.0               100000\n",
       "1.0               100000\n",
       "2.0                50000"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics of just the 2 classes used\n",
    "df_labeled.groupby('star_rating').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled=df_labeled[['review_body','star_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled.to_csv('dataset_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled=pd.read_csv('dataset_balanced.csv', usecols=['review_body','star_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Task 2 : Word Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 2A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity between Good and Evil:  0.20598836\n",
      "Semantic Similarity between Good and Excellent:  0.6442929\n",
      "We can see that Good is much more similary semantically to Excellent than Evil\n"
     ]
    }
   ],
   "source": [
    "print(\"Semantic Similarity between Good and Evil: \",wv.similarity(\"good\", \"evil\"))\n",
    "print(\"Semantic Similarity between Good and Excellent: \",wv.similarity(\"good\", \"excellent\"))\n",
    "print(\"We can see that Good is much more similary semantically to Excellent than Evil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kings', 0.7138045430183411), ('queen', 0.6510956883430481), ('monarch', 0.6413194537162781), ('crown_prince', 0.6204220056533813), ('prince', 0.6159993410110474)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar('king', topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 2B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for review in df_labeled[\"review_body\"]:\n",
    "            yield utils.simple_preprocess(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "model_w2v = gensim.models.Word2Vec(sentences=sentences, min_count=10, window=11, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "# model_w2v.save('Word2Vec_model.bin')\n",
    "# model_w2v = gensim.models.Word2Vec.load('Word2Vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity between Good and Evil:  0.0873883\n",
      "Semantic Similarity between Good and Excellent:  0.5899097\n",
      "We can see that the similarities have reduced in magnitude and Good and Evil has become even more smaller while there is a small impact on Excellent. After experimenting with other values, I feel the pre-build model worked better as it gave much higher similairties for similar items\n"
     ]
    }
   ],
   "source": [
    "print(\"Semantic Similarity between Good and Evil: \",model_w2v.wv.similarity(\"good\", \"evil\"))\n",
    "print(\"Semantic Similarity between Good and Excellent: \",model_w2v.wv.similarity(\"good\", \"excellent\"))\n",
    "print(\"We can see that the similarities have reduced in magnitude and Good and Evil has become even more smaller while there is a small impact on Excellent. After experimenting with other values, I feel the pre-build model worked better as it gave much higher similairties for similar items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Task 3 : Simple models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled['review_body']=df_labeled['review_body'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    text=str(text)\n",
    "    text = re.sub(clean, '', text)\n",
    "    return re.sub(r\"\\S*http\\S+\", \"\", text)\n",
    "\n",
    "df_labeled['review_body']=df_labeled['review_body'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractionfunction(s):\n",
    "    s=contractions.fix(s)\n",
    "    return s\n",
    "df_labeled['review_body']=df_labeled['review_body'].apply(contractionfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha(text):\n",
    "    clean = re.compile('[^a-zA-Z]+')\n",
    "    text=str(text)\n",
    "    return re.sub(clean, ' ', text)\n",
    "\n",
    "df_labeled['review_body']=df_labeled['review_body'].apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(text):\n",
    "     return re.sub(' +', ' ', str(text.strip()))\n",
    "\n",
    "df_labeled['review_body']=df_labeled['review_body'].apply(remove_extra_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### average character length after cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.634672\n"
     ]
    }
   ],
   "source": [
    "char_len_after = sum(df_labeled[\"review_body\"].str.len())/df_labeled.shape[0]\n",
    "print(char_len_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "stopwords_set = set(stopwords.words(\"english\"))                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_remove_stopwords(text):\n",
    "    text = ' '.join([wnl.lemmatize(word) for word in nltk.word_tokenize(text) if  word not in stopwords_set])\n",
    "    return text\n",
    "\n",
    "df_labeled['review_body']=df_labeled['review_body'].apply(lemmatize_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### average character length after preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.415288\n"
     ]
    }
   ],
   "source": [
    "char_len_after_prep = sum(df_labeled[\"review_body\"].str.len())/df_labeled.shape[0]\n",
    "print(char_len_after_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "df_labeled.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## sample review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214276</th>\n",
       "      <td>second one gave first gift friend use everyday...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150795</th>\n",
       "      <td>efficient chopping onion tomato vegetable draw...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124344</th>\n",
       "      <td>plastic really flimsy warp easily filter best ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58434</th>\n",
       "      <td>gingerbread bit stale</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171666</th>\n",
       "      <td>hour review figure said said main purpose writ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  star_rating\n",
       "214276  second one gave first gift friend use everyday...          1.0\n",
       "150795  efficient chopping onion tomato vegetable draw...          1.0\n",
       "124344  plastic really flimsy warp easily filter best ...          2.0\n",
       "58434                               gingerbread bit stale          0.0\n",
       "171666  hour review figure said said main purpose writ...          1.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "# df_labeled.to_csv('df_labeled_pre.csv')\n",
    "# df_labeled=pd.read_csv('df_labeled_pre.csv', usecols=['review_body','star_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Dataframe preperation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mymodel=[]\n",
    "list_prebuilt=[]\n",
    "empty_word2vec=[]\n",
    "for i in range(len(df_labeled)):\n",
    "    count_mymodel=0\n",
    "    count_prebuilt=0\n",
    "    list_temp_mymodel=np.zeros([300])\n",
    "    list_temp_prebuilt=np.zeros([300])\n",
    "    for word in nltk.word_tokenize(df_labeled.iloc[i,0]):\n",
    "        \n",
    "        if word in model_w2v.wv:\n",
    "            word_emb_mymodel = np.asarray(model_w2v.wv[word])\n",
    "            count_mymodel+=1\n",
    "            list_temp_mymodel+=word_emb_mymodel\n",
    "        \n",
    "        if word in wv:\n",
    "            word_emb_prebuilt = np.asarray(wv[word])\n",
    "            count_prebuilt+=1\n",
    "            list_temp_prebuilt+=word_emb_prebuilt\n",
    "         \n",
    "    if count_mymodel!=0:     \n",
    "        list_mymodel.append(np.append(list_temp_mymodel/count_mymodel,df_labeled.iloc[i,-1]))\n",
    "    if count_prebuilt!=0:\n",
    "        list_prebuilt.append(np.append(list_temp_prebuilt/count_prebuilt,df_labeled.iloc[i,-1]))\n",
    "    if count_mymodel==0 or count_prebuilt==0:\n",
    "        empty_word2vec.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.drop(empty_word2vec, inplace=True)\n",
    "df_labeled.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary=df_labeled[df_labeled[\"star_rating\"]!=2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mymodel_ternary = pd.DataFrame(data=list_mymodel)\n",
    "df_prebuilt_ternary = pd.DataFrame(data=list_prebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Infinite values\n",
    "df_prebuilt_ternary.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_mymodel_ternary.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop null values\n",
    "df_prebuilt_ternary.dropna(inplace=True)\n",
    "df_mymodel_ternary.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mymodel_binary=df_mymodel_ternary[df_mymodel_ternary[300]!=2.0]\n",
    "df_prebuilt_binary=df_prebuilt_ternary[df_prebuilt_ternary[300]!=2.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(df_binary[\"review_body\"], df_binary[\"star_rating\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel\n",
    "X_train_mymodel_binary, X_test_mymodel_binary, y_train_mymodel_binary, y_test_mymodel_binary = train_test_split(df_mymodel_binary.iloc[:,:-1].values, df_mymodel_binary.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prebuilt\n",
    "X_train_prebuilt, X_test_prebuilt, y_train_prebuilt, y_test_prebuilt = train_test_split(df_prebuilt_binary.iloc[:,:-1].values, df_prebuilt_binary.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel_ternary\n",
    "X_train_mymodel_ternary, X_test_mymodel_ternary, y_train_mymodel_ternary, y_test_mymodel_ternary = train_test_split(df_mymodel_ternary.iloc[:,:-1].values, df_mymodel_ternary.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prebuilt_ternary\n",
    "X_train_prebuilt_ternary, X_test_prebuilt_ternary, y_train_prebuilt_ternary, y_test_prebuilt_ternary = train_test_split(df_prebuilt_ternary.iloc[:,:-1].values, df_prebuilt_ternary.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TF-IDF feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf= vectorizer.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf=vectorizer.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "clf_tfidf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf=clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "#mymodel\n",
    "clf_mymodel = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_mymodel.fit(X_train_mymodel_binary, y_train_mymodel_binary)\n",
    "y_pred_mymodel_binary=clf_mymodel.predict(X_test_mymodel_binary)\n",
    "\n",
    "#prebuilt\n",
    "clf_prebuilt = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_prebuilt.fit(X_train_prebuilt, y_train_prebuilt)\n",
    "y_pred_prebuilt=clf_prebuilt.predict(X_test_prebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Perceptron----------\n",
      "----------TF-IDF----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.84      0.83     19973\n",
      "         1.0       0.84      0.81      0.82     19982\n",
      "\n",
      "    accuracy                           0.83     39955\n",
      "   macro avg       0.83      0.83      0.83     39955\n",
      "weighted avg       0.83      0.83      0.83     39955\n",
      "\n",
      "----------My Model----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.82      0.80     20004\n",
      "         1.0       0.81      0.76      0.78     19953\n",
      "\n",
      "    accuracy                           0.79     39957\n",
      "   macro avg       0.79      0.79      0.79     39957\n",
      "weighted avg       0.79      0.79      0.79     39957\n",
      "\n",
      "----------Pre-Built----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.95      0.77     19965\n",
      "         1.0       0.90      0.47      0.62     20002\n",
      "\n",
      "    accuracy                           0.71     39967\n",
      "   macro avg       0.77      0.71      0.69     39967\n",
      "weighted avg       0.77      0.71      0.69     39967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------Perceptron----------\")\n",
    "\n",
    "print(\"----------TF-IDF----------\")\n",
    "cl_report_tfidf=classification_report(y_test_tfidf, y_pred_tfidf, output_dict=True)\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf))\n",
    "\n",
    "print(\"----------My Model----------\")\n",
    "cl_report_mymodel=classification_report(y_test_mymodel_binary, y_pred_mymodel_binary, output_dict=True)\n",
    "print(classification_report(y_test_mymodel_binary, y_pred_mymodel_binary))\n",
    "\n",
    "print(\"----------Pre-Built----------\")\n",
    "cl_report_prebuilt=classification_report(y_test_prebuilt, y_pred_prebuilt, output_dict=True)\n",
    "print(classification_report(y_test_prebuilt, y_pred_prebuilt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "clf_tfidf = LinearSVC(random_state=0, tol=1e-5, max_iter=100)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf=clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# #mymodel\n",
    "clf_mymodel = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf_mymodel.fit(X_train_mymodel_binary, y_train_mymodel_binary)\n",
    "y_pred_mymodel_binary=clf_mymodel.predict(X_test_mymodel_binary)\n",
    "\n",
    "# #prebuilt\n",
    "clf_prebuilt = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf_prebuilt.fit(X_train_prebuilt, y_train_prebuilt)\n",
    "y_pred_prebuilt=clf_prebuilt.predict(X_test_prebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------SVM----------\n",
      "----------TF-IDF----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.87     19973\n",
      "         1.0       0.87      0.87      0.87     19982\n",
      "\n",
      "    accuracy                           0.87     39955\n",
      "   macro avg       0.87      0.87      0.87     39955\n",
      "weighted avg       0.87      0.87      0.87     39955\n",
      "\n",
      "----------My Model----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.85      0.84     20004\n",
      "         1.0       0.85      0.83      0.84     19953\n",
      "\n",
      "    accuracy                           0.84     39957\n",
      "   macro avg       0.84      0.84      0.84     39957\n",
      "weighted avg       0.84      0.84      0.84     39957\n",
      "\n",
      "----------Pre-Built----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82     19965\n",
      "         1.0       0.83      0.80      0.81     20002\n",
      "\n",
      "    accuracy                           0.82     39967\n",
      "   macro avg       0.82      0.82      0.82     39967\n",
      "weighted avg       0.82      0.82      0.82     39967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------SVM----------\")\n",
    "\n",
    "print(\"----------TF-IDF----------\")\n",
    "cl_report_tfidf=classification_report(y_test_tfidf, y_pred_tfidf, output_dict=True)\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf))\n",
    "\n",
    "print(\"----------My Model----------\")\n",
    "cl_report_mymodel=classification_report(y_test_mymodel_binary, y_pred_mymodel_binary, output_dict=True)\n",
    "print(classification_report(y_test_mymodel_binary, y_pred_mymodel_binary))\n",
    "\n",
    "print(\"----------Pre-Built----------\")\n",
    "cl_report_prebuilt=classification_report(y_test_prebuilt, y_pred_prebuilt, output_dict=True)\n",
    "print(classification_report(y_test_prebuilt, y_pred_prebuilt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 : Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "        self.len = features.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        row=self.features[index,:]\n",
    "        row_label=self.labels[index]\n",
    "        return row,row_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_generator, model, n_epochs, lr):\n",
    "    # specify loss function (categorical cross-entropy)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    loss_values = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train() # prep model for training\n",
    "        for local_data, target in training_generator:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(local_data)\n",
    "\n",
    "            loss = criterion(output, target.type(torch.LongTensor))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*local_data.size(0)\n",
    "        \n",
    "        train_loss = train_loss/len(training_generator.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss,\n",
    "            ))\n",
    "        loss_values.append(train_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the NN architecture\n",
    "class Net_bin(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(Net_bin, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 50\n",
    "        hidden_2 = 10\n",
    "      \n",
    "        self.fc1 = nn.Linear(300, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, output_size)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model_binary = Net_bin(output_size=2)\n",
    "print(model_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_mymodel_binary, y_train_mymodel_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.682409\n",
      "Epoch: 2 \tTraining Loss: 0.613176\n",
      "Epoch: 3 \tTraining Loss: 0.524642\n",
      "Epoch: 4 \tTraining Loss: 0.481360\n",
      "Epoch: 5 \tTraining Loss: 0.457034\n",
      "Epoch: 6 \tTraining Loss: 0.439227\n",
      "Epoch: 7 \tTraining Loss: 0.426178\n",
      "Epoch: 8 \tTraining Loss: 0.415912\n",
      "Epoch: 9 \tTraining Loss: 0.409563\n",
      "Epoch: 10 \tTraining Loss: 0.402036\n",
      "Epoch: 11 \tTraining Loss: 0.398236\n",
      "Epoch: 12 \tTraining Loss: 0.393365\n",
      "Epoch: 13 \tTraining Loss: 0.390367\n",
      "Epoch: 14 \tTraining Loss: 0.387317\n",
      "Epoch: 15 \tTraining Loss: 0.384438\n",
      "Epoch: 16 \tTraining Loss: 0.382616\n",
      "Epoch: 17 \tTraining Loss: 0.381207\n",
      "Epoch: 18 \tTraining Loss: 0.379443\n",
      "Epoch: 19 \tTraining Loss: 0.377797\n",
      "Epoch: 20 \tTraining Loss: 0.376551\n"
     ]
    }
   ],
   "source": [
    "model_binary=train_model(training_generator, model_binary, n_epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = torch.max(model_binary(torch.Tensor(X_test_mymodel_binary)),1)\n",
    "predictions=predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.83      0.84     20004\n",
      "         1.0       0.83      0.84      0.84     19953\n",
      "\n",
      "    accuracy                           0.84     39957\n",
      "   macro avg       0.84      0.84      0.84     39957\n",
      "weighted avg       0.84      0.84      0.84     39957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_prebuilt=classification_report(y_test_mymodel_binary, predictions, output_dict=True)\n",
    "print(classification_report(y_test_mymodel_binary, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_binary = Net_bin(output_size=2)\n",
    "print(model_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_prebuilt, y_train_prebuilt)\n",
    "training_generator = data.DataLoader(training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.693409\n",
      "Epoch: 2 \tTraining Loss: 0.693032\n",
      "Epoch: 3 \tTraining Loss: 0.692660\n",
      "Epoch: 4 \tTraining Loss: 0.691964\n",
      "Epoch: 5 \tTraining Loss: 0.691203\n",
      "Epoch: 6 \tTraining Loss: 0.689850\n",
      "Epoch: 7 \tTraining Loss: 0.688258\n",
      "Epoch: 8 \tTraining Loss: 0.685967\n",
      "Epoch: 9 \tTraining Loss: 0.682848\n",
      "Epoch: 10 \tTraining Loss: 0.678540\n",
      "Epoch: 11 \tTraining Loss: 0.672079\n",
      "Epoch: 12 \tTraining Loss: 0.663336\n",
      "Epoch: 13 \tTraining Loss: 0.650485\n",
      "Epoch: 14 \tTraining Loss: 0.633019\n",
      "Epoch: 15 \tTraining Loss: 0.611667\n",
      "Epoch: 16 \tTraining Loss: 0.587206\n",
      "Epoch: 17 \tTraining Loss: 0.563649\n",
      "Epoch: 18 \tTraining Loss: 0.544071\n",
      "Epoch: 19 \tTraining Loss: 0.528583\n",
      "Epoch: 20 \tTraining Loss: 0.514886\n"
     ]
    }
   ],
   "source": [
    "model_binary=train_model(training_generator, model_binary, n_epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = torch.max(model_binary(torch.Tensor(X_test_prebuilt)),1)\n",
    "predictions=predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76     19965\n",
      "         1.0       0.77      0.75      0.76     20002\n",
      "\n",
      "    accuracy                           0.76     39967\n",
      "   macro avg       0.76      0.76      0.76     39967\n",
      "weighted avg       0.76      0.76      0.76     39967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_prebuilt=classification_report(y_test_prebuilt, predictions, output_dict=True)\n",
    "print(classification_report(y_test_prebuilt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_ternary = Net_bin(output_size=3)\n",
    "print(model_ternary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_mymodel_ternary, y_train_mymodel_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.883107\n",
      "Epoch: 2 \tTraining Loss: 0.786406\n",
      "Epoch: 3 \tTraining Loss: 0.769730\n",
      "Epoch: 4 \tTraining Loss: 0.758912\n",
      "Epoch: 5 \tTraining Loss: 0.752620\n",
      "Epoch: 6 \tTraining Loss: 0.746356\n",
      "Epoch: 7 \tTraining Loss: 0.742579\n",
      "Epoch: 8 \tTraining Loss: 0.738241\n",
      "Epoch: 9 \tTraining Loss: 0.734611\n",
      "Epoch: 10 \tTraining Loss: 0.731602\n",
      "Epoch: 11 \tTraining Loss: 0.729157\n",
      "Epoch: 12 \tTraining Loss: 0.726867\n",
      "Epoch: 13 \tTraining Loss: 0.723501\n",
      "Epoch: 14 \tTraining Loss: 0.723181\n",
      "Epoch: 15 \tTraining Loss: 0.719598\n",
      "Epoch: 16 \tTraining Loss: 0.718858\n",
      "Epoch: 17 \tTraining Loss: 0.716493\n",
      "Epoch: 18 \tTraining Loss: 0.716961\n",
      "Epoch: 19 \tTraining Loss: 0.714315\n",
      "Epoch: 20 \tTraining Loss: 0.712818\n",
      "Epoch: 21 \tTraining Loss: 0.711524\n",
      "Epoch: 22 \tTraining Loss: 0.710509\n",
      "Epoch: 23 \tTraining Loss: 0.710020\n",
      "Epoch: 24 \tTraining Loss: 0.708535\n",
      "Epoch: 25 \tTraining Loss: 0.708730\n",
      "Epoch: 26 \tTraining Loss: 0.707423\n",
      "Epoch: 27 \tTraining Loss: 0.706796\n",
      "Epoch: 28 \tTraining Loss: 0.705185\n",
      "Epoch: 29 \tTraining Loss: 0.704158\n",
      "Epoch: 30 \tTraining Loss: 0.702412\n",
      "Epoch: 31 \tTraining Loss: 0.702491\n",
      "Epoch: 32 \tTraining Loss: 0.701394\n",
      "Epoch: 33 \tTraining Loss: 0.701715\n",
      "Epoch: 34 \tTraining Loss: 0.700202\n",
      "Epoch: 35 \tTraining Loss: 0.698335\n",
      "Epoch: 36 \tTraining Loss: 0.699655\n",
      "Epoch: 37 \tTraining Loss: 0.698230\n",
      "Epoch: 38 \tTraining Loss: 0.697316\n",
      "Epoch: 39 \tTraining Loss: 0.698148\n",
      "Epoch: 40 \tTraining Loss: 0.697572\n",
      "Epoch: 41 \tTraining Loss: 0.695808\n",
      "Epoch: 42 \tTraining Loss: 0.696684\n",
      "Epoch: 43 \tTraining Loss: 0.695137\n",
      "Epoch: 44 \tTraining Loss: 0.694725\n",
      "Epoch: 45 \tTraining Loss: 0.694550\n",
      "Epoch: 46 \tTraining Loss: 0.692405\n",
      "Epoch: 47 \tTraining Loss: 0.692744\n",
      "Epoch: 48 \tTraining Loss: 0.693900\n",
      "Epoch: 49 \tTraining Loss: 0.691580\n",
      "Epoch: 50 \tTraining Loss: 0.693646\n"
     ]
    }
   ],
   "source": [
    "model_ternary=train_model(training_generator, model_ternary, n_epochs=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = torch.max(model_ternary(torch.Tensor(X_test_mymodel_ternary)),1)\n",
    "predictions=predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.83      0.75     19892\n",
      "         1.0       0.73      0.83      0.77     20153\n",
      "         2.0       0.44      0.14      0.21      9902\n",
      "\n",
      "    accuracy                           0.69     49947\n",
      "   macro avg       0.62      0.60      0.58     49947\n",
      "weighted avg       0.65      0.69      0.65     49947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_prebuilt=classification_report(y_test_mymodel_ternary, predictions, output_dict=True)\n",
    "print(classification_report(y_test_mymodel_ternary, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_ternary = Net_bin(output_size=3)\n",
    "print(model_ternary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_prebuilt_ternary, y_train_prebuilt_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.057546\n",
      "Epoch: 2 \tTraining Loss: 1.053613\n",
      "Epoch: 3 \tTraining Loss: 1.045289\n",
      "Epoch: 4 \tTraining Loss: 0.993860\n",
      "Epoch: 5 \tTraining Loss: 0.922670\n",
      "Epoch: 6 \tTraining Loss: 0.879874\n",
      "Epoch: 7 \tTraining Loss: 0.859903\n",
      "Epoch: 8 \tTraining Loss: 0.847216\n",
      "Epoch: 9 \tTraining Loss: 0.837847\n",
      "Epoch: 10 \tTraining Loss: 0.830215\n",
      "Epoch: 11 \tTraining Loss: 0.825294\n",
      "Epoch: 12 \tTraining Loss: 0.822504\n",
      "Epoch: 13 \tTraining Loss: 0.819849\n",
      "Epoch: 14 \tTraining Loss: 0.817067\n",
      "Epoch: 15 \tTraining Loss: 0.814475\n",
      "Epoch: 16 \tTraining Loss: 0.813459\n",
      "Epoch: 17 \tTraining Loss: 0.811938\n",
      "Epoch: 18 \tTraining Loss: 0.811020\n",
      "Epoch: 19 \tTraining Loss: 0.808682\n",
      "Epoch: 20 \tTraining Loss: 0.808509\n",
      "Epoch: 21 \tTraining Loss: 0.806614\n",
      "Epoch: 22 \tTraining Loss: 0.805619\n",
      "Epoch: 23 \tTraining Loss: 0.804396\n",
      "Epoch: 24 \tTraining Loss: 0.803214\n",
      "Epoch: 25 \tTraining Loss: 0.801834\n",
      "Epoch: 26 \tTraining Loss: 0.799392\n",
      "Epoch: 27 \tTraining Loss: 0.798673\n",
      "Epoch: 28 \tTraining Loss: 0.796322\n",
      "Epoch: 29 \tTraining Loss: 0.795395\n",
      "Epoch: 30 \tTraining Loss: 0.793542\n",
      "Epoch: 31 \tTraining Loss: 0.791256\n",
      "Epoch: 32 \tTraining Loss: 0.788774\n",
      "Epoch: 33 \tTraining Loss: 0.787598\n",
      "Epoch: 34 \tTraining Loss: 0.787591\n",
      "Epoch: 35 \tTraining Loss: 0.784772\n",
      "Epoch: 36 \tTraining Loss: 0.783389\n",
      "Epoch: 37 \tTraining Loss: 0.783233\n",
      "Epoch: 38 \tTraining Loss: 0.781469\n",
      "Epoch: 39 \tTraining Loss: 0.779929\n",
      "Epoch: 40 \tTraining Loss: 0.779491\n",
      "Epoch: 41 \tTraining Loss: 0.778134\n",
      "Epoch: 42 \tTraining Loss: 0.777085\n",
      "Epoch: 43 \tTraining Loss: 0.775661\n",
      "Epoch: 44 \tTraining Loss: 0.773954\n",
      "Epoch: 45 \tTraining Loss: 0.773000\n",
      "Epoch: 46 \tTraining Loss: 0.773140\n",
      "Epoch: 47 \tTraining Loss: 0.771384\n",
      "Epoch: 48 \tTraining Loss: 0.771177\n",
      "Epoch: 49 \tTraining Loss: 0.770093\n",
      "Epoch: 50 \tTraining Loss: 0.769189\n"
     ]
    }
   ],
   "source": [
    "model_ternary=train_model(training_generator, model_ternary, n_epochs=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = torch.max(model_ternary(torch.Tensor(X_test_prebuilt_ternary)),1)\n",
    "predictions=predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.82      0.73     19875\n",
      "         1.0       0.71      0.79      0.75     20101\n",
      "         2.0       0.42      0.12      0.19      9984\n",
      "\n",
      "    accuracy                           0.67     49960\n",
      "   macro avg       0.60      0.58      0.55     49960\n",
      "weighted avg       0.63      0.67      0.63     49960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_prebuilt=classification_report(y_test_prebuilt_ternary, predictions, output_dict=True)\n",
    "print(classification_report(y_test_prebuilt_ternary, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mymodel=[]\n",
    "temp_tensor=torch.ones(10,300)\n",
    "for i in range(len(df_labeled)):\n",
    "    count=0\n",
    "    for word in nltk.word_tokenize(df_labeled.iloc[i,0]):\n",
    "\n",
    "            \n",
    "        try:\n",
    "            word_emb = np.asarray(model_w2v.wv[word])\n",
    "            if count==0:\n",
    "                list_temp=word_emb.reshape(1,300)\n",
    "            else:\n",
    "                list_temp=np.vstack((list_temp,word_emb))\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        \n",
    "        if count==10:\n",
    "            break\n",
    "\n",
    "    list_mymodel.append(pad_sequence([temp_tensor,torch.tensor(list_temp)], True)[1].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_mymodel_ternary = df_labeled.sample(frac = 0.8).index\n",
    "list_test_mymodel_ternary = df_labeled.drop(list_train_mymodel_ternary).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prebuilt=[]\n",
    "temp_tensor=torch.ones(10,300)\n",
    "for i in range(len(df_labeled)):\n",
    "    count=0\n",
    "    for word in nltk.word_tokenize(df_labeled.iloc[i,0]):\n",
    "\n",
    "            \n",
    "        try:\n",
    "            word_emb = np.asarray(wv[word])\n",
    "            if count==0:\n",
    "                list_temp=word_emb.reshape(1,300)\n",
    "            else:\n",
    "                list_temp=np.vstack((list_temp,word_emb))\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        \n",
    "        if count==10:\n",
    "            break\n",
    "\n",
    "    list_prebuilt.append(pad_sequence([temp_tensor,torch.tensor(list_temp)], True)[1].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_prebuilt_ternary = df_labeled.sample(frac = 0.8).index\n",
    "list_test_prebuilt_ternary = df_labeled.drop(list_train_prebuilt_ternary).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "class myDataset(data.Dataset):\n",
    "    def __init__(self, list_model, df_labels, features_index_list):\n",
    "        self.features_index_list=features_index_list\n",
    "        self.df_labels=df_labels\n",
    "        self.list_model=list_model\n",
    "        self.len = len(self.features_index_list)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        row=self.list_model[self.features_index_list[index]]\n",
    "        row_label=self.df_labels[self.features_index_list[index]]\n",
    "        return row,row_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_ter(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class Net_ter(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(Net_ter, self).__init__()\n",
    "        hidden_1 = 50\n",
    "        hidden_2 = 10\n",
    "      \n",
    "        self.fc1 = nn.Linear(300*10, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, output_size)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.type(torch.FloatTensor).reshape(-1,300*10)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model_ternary = Net_ter(output_size=3)\n",
    "print(model_ternary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(list_mymodel, df_labeled.iloc[:,-1], list_train_mymodel_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.002745\n",
      "Epoch: 2 \tTraining Loss: 0.929227\n",
      "Epoch: 3 \tTraining Loss: 0.901097\n",
      "Epoch: 4 \tTraining Loss: 0.883688\n",
      "Epoch: 5 \tTraining Loss: 0.869640\n",
      "Epoch: 6 \tTraining Loss: 0.859142\n",
      "Epoch: 7 \tTraining Loss: 0.850714\n",
      "Epoch: 8 \tTraining Loss: 0.843251\n",
      "Epoch: 9 \tTraining Loss: 0.836320\n",
      "Epoch: 10 \tTraining Loss: 0.830435\n",
      "Epoch: 11 \tTraining Loss: 0.825203\n",
      "Epoch: 12 \tTraining Loss: 0.817989\n",
      "Epoch: 13 \tTraining Loss: 0.814520\n",
      "Epoch: 14 \tTraining Loss: 0.810111\n",
      "Epoch: 15 \tTraining Loss: 0.804028\n",
      "Epoch: 16 \tTraining Loss: 0.800475\n",
      "Epoch: 17 \tTraining Loss: 0.797352\n",
      "Epoch: 18 \tTraining Loss: 0.791817\n",
      "Epoch: 19 \tTraining Loss: 0.786255\n",
      "Epoch: 20 \tTraining Loss: 0.783807\n"
     ]
    }
   ],
   "source": [
    "model_ternary=train_model(training_generator, model_ternary, n_epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mymodel_ternary=[list_mymodel[i] for i in list_test_mymodel_ternary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ter=[]\n",
    "for test_batch in test_mymodel_ternary:\n",
    "    _, predictions = torch.max(model_ternary(test_batch),1)\n",
    "    predictions=predictions.numpy()\n",
    "    y_pred_ter.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.75      0.69     19990\n",
      "         1.0       0.65      0.76      0.70     19933\n",
      "         2.0       0.42      0.13      0.20     10021\n",
      "\n",
      "    accuracy                           0.63     49944\n",
      "   macro avg       0.57      0.55      0.53     49944\n",
      "weighted avg       0.60      0.63      0.59     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_ter=classification_report(df_labeled.iloc[list_test_mymodel_ternary,-1], y_pred_ter, output_dict=True)\n",
    "print(classification_report(df_labeled.iloc[list_test_mymodel_ternary,-1], y_pred_ter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(list_prebuilt, df_labeled.iloc[:,-1], list_train_prebuilt_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_ter(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_ternary = Net_ter(output_size=3)\n",
    "print(model_ternary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.032913\n",
      "Epoch: 2 \tTraining Loss: 0.947315\n",
      "Epoch: 3 \tTraining Loss: 0.908351\n",
      "Epoch: 4 \tTraining Loss: 0.889106\n",
      "Epoch: 5 \tTraining Loss: 0.877799\n",
      "Epoch: 6 \tTraining Loss: 0.867469\n",
      "Epoch: 7 \tTraining Loss: 0.860476\n",
      "Epoch: 8 \tTraining Loss: 0.854139\n",
      "Epoch: 9 \tTraining Loss: 0.848138\n",
      "Epoch: 10 \tTraining Loss: 0.843173\n",
      "Epoch: 11 \tTraining Loss: 0.838382\n",
      "Epoch: 12 \tTraining Loss: 0.833776\n",
      "Epoch: 13 \tTraining Loss: 0.828013\n",
      "Epoch: 14 \tTraining Loss: 0.824496\n",
      "Epoch: 15 \tTraining Loss: 0.819308\n",
      "Epoch: 16 \tTraining Loss: 0.814039\n",
      "Epoch: 17 \tTraining Loss: 0.810289\n",
      "Epoch: 18 \tTraining Loss: 0.804642\n",
      "Epoch: 19 \tTraining Loss: 0.799210\n",
      "Epoch: 20 \tTraining Loss: 0.793725\n"
     ]
    }
   ],
   "source": [
    "model_ternary=train_model(training_generator, model_ternary, n_epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prebuilt_ternary=[list_prebuilt[i] for i in list_test_prebuilt_ternary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ter=[]\n",
    "for test_batch in test_prebuilt_ternary:\n",
    "    _, predictions = torch.max(model_ternary(test_batch),1)\n",
    "    predictions=predictions.numpy()\n",
    "    y_pred_ter.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.75      0.68     19957\n",
      "         1.0       0.65      0.74      0.69     20052\n",
      "         2.0       0.41      0.13      0.19      9935\n",
      "\n",
      "    accuracy                           0.62     49944\n",
      "   macro avg       0.56      0.54      0.52     49944\n",
      "weighted avg       0.59      0.62      0.59     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_ter=classification_report(df_labeled.iloc[list_test_prebuilt_ternary,-1], y_pred_ter, output_dict=True)\n",
    "print(classification_report(df_labeled.iloc[list_test_prebuilt_ternary,-1], y_pred_ter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary_indexed=df_labeled.drop(df_labeled[df_labeled['star_rating']==2].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_mymodel_binary = df_binary_indexed.sample(frac = 0.8).index\n",
    "list_test_mymodel_binary = df_binary_indexed.drop(list_train_mymodel_binary).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(list_mymodel, df_binary_indexed.iloc[:,-1], list_train_mymodel_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_binary = Net_ter(output_size=2)\n",
    "print(model_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.645827\n",
      "Epoch: 2 \tTraining Loss: 0.546711\n",
      "Epoch: 3 \tTraining Loss: 0.515771\n",
      "Epoch: 4 \tTraining Loss: 0.496976\n",
      "Epoch: 5 \tTraining Loss: 0.483101\n",
      "Epoch: 6 \tTraining Loss: 0.474836\n",
      "Epoch: 7 \tTraining Loss: 0.465672\n",
      "Epoch: 8 \tTraining Loss: 0.459892\n",
      "Epoch: 9 \tTraining Loss: 0.453065\n",
      "Epoch: 10 \tTraining Loss: 0.448516\n",
      "Epoch: 11 \tTraining Loss: 0.443470\n",
      "Epoch: 12 \tTraining Loss: 0.438487\n",
      "Epoch: 13 \tTraining Loss: 0.433792\n",
      "Epoch: 14 \tTraining Loss: 0.428711\n",
      "Epoch: 15 \tTraining Loss: 0.424195\n",
      "Epoch: 16 \tTraining Loss: 0.420590\n",
      "Epoch: 17 \tTraining Loss: 0.415587\n",
      "Epoch: 18 \tTraining Loss: 0.411432\n",
      "Epoch: 19 \tTraining Loss: 0.407033\n",
      "Epoch: 20 \tTraining Loss: 0.403376\n"
     ]
    }
   ],
   "source": [
    "model_binary=train_model(training_generator, model_binary, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mymodel_binary=[list_mymodel[i] for i in list_test_mymodel_binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin=[]\n",
    "for test_batch in test_mymodel_binary:\n",
    "    _, predictions = torch.max(model_binary(test_batch),1)\n",
    "    predictions=predictions.numpy()\n",
    "    y_pred_bin.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.79      0.78     19879\n",
      "         1.0       0.79      0.77      0.78     20076\n",
      "\n",
      "    accuracy                           0.78     39955\n",
      "   macro avg       0.78      0.78      0.78     39955\n",
      "weighted avg       0.78      0.78      0.78     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_bin=classification_report(df_binary_indexed.loc[list_test_mymodel_binary]['star_rating'], y_pred_bin, output_dict=True)\n",
    "print(classification_report(df_binary_indexed.loc[list_test_mymodel_binary]['star_rating'], y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary_indexed=df_labeled.drop(df_labeled[df_labeled['star_rating']==2].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_prebuilt_binary = df_binary_indexed.sample(frac = 0.8).index\n",
    "list_test_prebuilt_binary = df_binary_indexed.drop(list_train_prebuilt_binary).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(list_prebuilt, df_binary_indexed.iloc[:,-1], list_train_prebuilt_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_bin(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the NN\n",
    "model_binary = Net_ter(output_size=2)\n",
    "print(model_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.692747\n",
      "Epoch: 2 \tTraining Loss: 0.689540\n",
      "Epoch: 3 \tTraining Loss: 0.680256\n",
      "Epoch: 4 \tTraining Loss: 0.661752\n",
      "Epoch: 5 \tTraining Loss: 0.630659\n",
      "Epoch: 6 \tTraining Loss: 0.595139\n",
      "Epoch: 7 \tTraining Loss: 0.567392\n",
      "Epoch: 8 \tTraining Loss: 0.550157\n",
      "Epoch: 9 \tTraining Loss: 0.539487\n",
      "Epoch: 10 \tTraining Loss: 0.530948\n",
      "Epoch: 11 \tTraining Loss: 0.523500\n",
      "Epoch: 12 \tTraining Loss: 0.518405\n",
      "Epoch: 13 \tTraining Loss: 0.513158\n",
      "Epoch: 14 \tTraining Loss: 0.509051\n",
      "Epoch: 15 \tTraining Loss: 0.504877\n",
      "Epoch: 16 \tTraining Loss: 0.500806\n",
      "Epoch: 17 \tTraining Loss: 0.498415\n",
      "Epoch: 18 \tTraining Loss: 0.495142\n",
      "Epoch: 19 \tTraining Loss: 0.492861\n",
      "Epoch: 20 \tTraining Loss: 0.490396\n"
     ]
    }
   ],
   "source": [
    "model_binary=train_model(training_generator, model_binary, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prebuilt_binary=[list_prebuilt[i] for i in list_test_prebuilt_binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin=[]\n",
    "for test_batch in test_prebuilt_binary:\n",
    "    _, predictions = torch.max(model_binary(test_batch),1)\n",
    "    predictions=predictions.numpy()\n",
    "    y_pred_bin.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77     19967\n",
      "         1.0       0.77      0.74      0.76     19988\n",
      "\n",
      "    accuracy                           0.76     39955\n",
      "   macro avg       0.76      0.76      0.76     39955\n",
      "weighted avg       0.76      0.76      0.76     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_report_bin=classification_report(df_binary_indexed.loc[list_test_prebuilt_binary]['star_rating'], y_pred_bin, output_dict=True)\n",
    "print(classification_report(df_binary_indexed.loc[list_test_prebuilt_binary]['star_rating'], y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 : Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "        self.len = features.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "#         row_tensor=self.features[index]\n",
    "  \n",
    "        \n",
    "        \n",
    "        list_rnn=[]\n",
    "        count=0\n",
    "        temp_tensor=torch.ones(50,300)\n",
    "        for word in nltk.word_tokenize(self.features[index]):\n",
    "            \n",
    "            try:\n",
    "                word_emb = np.asarray(model_w2v.wv[word])\n",
    "                if count==0:\n",
    "                    list_rnn=word_emb\n",
    "                else:\n",
    "                    list_rnn=np.append([list_rnn],word_emb)\n",
    "                count+=1\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            if count==50:\n",
    "                break\n",
    "\n",
    "        \n",
    "        if len(list_rnn)!=0:\n",
    "            return pad_sequence([temp_tensor,torch.tensor(list_rnn.reshape(-1,300))], True)[1],self.labels[index], count-1\n",
    "#         else:\n",
    "#             return torch.zeros(50,300),self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prebuiltDataset(data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "        self.len = features.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "#         row_tensor=self.features[index]\n",
    "  \n",
    "        \n",
    "        \n",
    "        list_rnn=[]\n",
    "        count=0\n",
    "        temp_tensor=torch.ones(50,300)\n",
    "        for word in nltk.word_tokenize(self.features[index]):\n",
    "            \n",
    "            try:\n",
    "                word_emb = np.asarray(wv[word])\n",
    "                if count==0:\n",
    "                    list_rnn=word_emb\n",
    "                else:\n",
    "                    list_rnn=np.append([list_rnn],word_emb)\n",
    "                count+=1\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            if count==50:\n",
    "                break\n",
    "\n",
    "        \n",
    "        if len(list_rnn)!=0:\n",
    "            return pad_sequence([temp_tensor,torch.tensor(list_rnn.reshape(-1,300))], True)[1],self.labels[index], count-1\n",
    "#         else:\n",
    "#             return torch.zeros(50,300),self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_ternary\n",
    "X_train_rnn_ternary, X_test_rnn_ternary, y_train_rnn_ternary, y_test_rnn_ternary = train_test_split(df_labeled.iloc[:,0].values, df_labeled.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        \n",
    "        super(Model_RNN, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        #activation function\n",
    "#         self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, x_length):\n",
    "   \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        out = out[torch.arange(batch_size),x_length,:].reshape(1,batch_size,self.hidden_dim)\n",
    "        dense_outputs=self.fc(out)\n",
    "        \n",
    "\n",
    "        output = self.softmax(dense_outputs)\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_RNN(input_size=300, output_size=3, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    for x_input, y_label, x_length in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        output= model(x_input, x_length).squeeze()\n",
    "  \n",
    "        #compute the loss\n",
    "        loss = criterion(output, y_label.long())        \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "#         acc = binary_accuracy(output, batch.label)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()     \n",
    "        \n",
    "        #clip gradient, to prevent from exploding\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "#         epoch_acc += acc.item()    \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "# , epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_rnn_ternary, y_train_rnn_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.678\n",
      "Epoch: 1\tTrain Loss: 0.479\n",
      "Epoch: 2\tTrain Loss: 0.450\n",
      "Epoch: 3\tTrain Loss: 0.435\n",
      "Epoch: 4\tTrain Loss: 0.423\n",
      "Epoch: 5\tTrain Loss: 0.414\n",
      "Epoch: 6\tTrain Loss: 0.407\n",
      "Epoch: 7\tTrain Loss: 0.399\n",
      "Epoch: 8\tTrain Loss: 0.393\n",
      "Epoch: 9\tTrain Loss: 0.388\n",
      "Epoch: 10\tTrain Loss: 0.381\n",
      "Epoch: 11\tTrain Loss: 0.376\n",
      "Epoch: 12\tTrain Loss: 0.371\n",
      "Epoch: 13\tTrain Loss: 0.367\n",
      "Epoch: 14\tTrain Loss: 0.363\n",
      "Epoch: 15\tTrain Loss: 0.360\n",
      "Epoch: 16\tTrain Loss: 0.355\n",
      "Epoch: 17\tTrain Loss: 0.352\n",
      "Epoch: 18\tTrain Loss: 0.349\n",
      "Epoch: 19\tTrain Loss: 0.346\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=myDataset(X_test_rnn_ternary, y_test_rnn_ternary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.69      0.76     24334\n",
      "         1.0       0.87      0.71      0.78     24742\n",
      "         2.0       0.02      0.27      0.04       868\n",
      "\n",
      "    accuracy                           0.69     49944\n",
      "   macro avg       0.58      0.56      0.53     49944\n",
      "weighted avg       0.84      0.69      0.76     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - Prebuilt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=prebuiltDataset(X_train_rnn_ternary, y_train_rnn_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_RNN(input_size=300, output_size=3, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.912\n",
      "Epoch: 1\tTrain Loss: 0.835\n",
      "Epoch: 2\tTrain Loss: 0.800\n",
      "Epoch: 3\tTrain Loss: 0.790\n",
      "Epoch: 4\tTrain Loss: 0.783\n",
      "Epoch: 5\tTrain Loss: 0.776\n",
      "Epoch: 6\tTrain Loss: 0.770\n",
      "Epoch: 7\tTrain Loss: 0.765\n",
      "Epoch: 8\tTrain Loss: 0.761\n",
      "Epoch: 9\tTrain Loss: 0.757\n",
      "Epoch: 10\tTrain Loss: 0.754\n",
      "Epoch: 11\tTrain Loss: 0.750\n",
      "Epoch: 12\tTrain Loss: 0.745\n",
      "Epoch: 13\tTrain Loss: 0.741\n",
      "Epoch: 14\tTrain Loss: 0.737\n",
      "Epoch: 15\tTrain Loss: 0.734\n",
      "Epoch: 16\tTrain Loss: 0.730\n",
      "Epoch: 17\tTrain Loss: 0.726\n",
      "Epoch: 18\tTrain Loss: 0.722\n",
      "Epoch: 19\tTrain Loss: 0.719\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=prebuiltDataset(X_test_rnn_ternary, y_test_rnn_ternary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.69      0.75     23299\n",
      "         1.0       0.79      0.74      0.77     21569\n",
      "         2.0       0.22      0.42      0.29      5076\n",
      "\n",
      "    accuracy                           0.69     49944\n",
      "   macro avg       0.61      0.62      0.60     49944\n",
      "weighted avg       0.75      0.69      0.71     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_ternary\n",
    "X_train_rnn_binary, X_test_rnn_binary, y_train_rnn_binary, y_test_rnn_binary = train_test_split(df_binary.iloc[:,0].values, df_binary.iloc[:,-1].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_RNN(input_size=300, output_size=2, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_rnn_binary, y_train_rnn_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.537\n",
      "Epoch: 1\tTrain Loss: 0.425\n",
      "Epoch: 2\tTrain Loss: 0.406\n",
      "Epoch: 3\tTrain Loss: 0.393\n",
      "Epoch: 4\tTrain Loss: 0.383\n",
      "Epoch: 5\tTrain Loss: 0.377\n",
      "Epoch: 6\tTrain Loss: 0.370\n",
      "Epoch: 7\tTrain Loss: 0.364\n",
      "Epoch: 8\tTrain Loss: 0.359\n",
      "Epoch: 9\tTrain Loss: 0.356\n",
      "Epoch: 10\tTrain Loss: 0.351\n",
      "Epoch: 11\tTrain Loss: 0.348\n",
      "Epoch: 12\tTrain Loss: 0.344\n",
      "Epoch: 13\tTrain Loss: 0.341\n",
      "Epoch: 14\tTrain Loss: 0.339\n",
      "Epoch: 15\tTrain Loss: 0.335\n",
      "Epoch: 16\tTrain Loss: 0.334\n",
      "Epoch: 17\tTrain Loss: 0.330\n",
      "Epoch: 18\tTrain Loss: 0.328\n",
      "Epoch: 19\tTrain Loss: 0.326\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=myDataset(X_test_rnn_binary, y_test_rnn_binary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85     19207\n",
      "         1.0       0.87      0.84      0.85     20748\n",
      "\n",
      "    accuracy                           0.85     39955\n",
      "   macro avg       0.85      0.85      0.85     39955\n",
      "weighted avg       0.85      0.85      0.85     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=prebuiltDataset(X_train_rnn_binary, y_train_rnn_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_RNN(input_size=300, output_size=2, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.482\n",
      "Epoch: 1\tTrain Loss: 0.427\n",
      "Epoch: 2\tTrain Loss: 0.414\n",
      "Epoch: 3\tTrain Loss: 0.401\n",
      "Epoch: 4\tTrain Loss: 0.396\n",
      "Epoch: 5\tTrain Loss: 0.390\n",
      "Epoch: 6\tTrain Loss: 0.387\n",
      "Epoch: 7\tTrain Loss: 0.382\n",
      "Epoch: 8\tTrain Loss: 0.377\n",
      "Epoch: 9\tTrain Loss: 0.371\n",
      "Epoch: 10\tTrain Loss: 0.367\n",
      "Epoch: 11\tTrain Loss: 0.361\n",
      "Epoch: 12\tTrain Loss: 0.356\n",
      "Epoch: 13\tTrain Loss: 0.351\n",
      "Epoch: 14\tTrain Loss: 0.346\n",
      "Epoch: 15\tTrain Loss: 0.342\n",
      "Epoch: 16\tTrain Loss: 0.337\n",
      "Epoch: 17\tTrain Loss: 0.333\n",
      "Epoch: 18\tTrain Loss: 0.330\n",
      "Epoch: 19\tTrain Loss: 0.327\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=prebuiltDataset(X_test_rnn_binary, y_test_rnn_binary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86     19555\n",
      "         1.0       0.87      0.85      0.86     20400\n",
      "\n",
      "    accuracy                           0.86     39955\n",
      "   macro avg       0.86      0.86      0.86     39955\n",
      "weighted avg       0.86      0.86      0.86     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5b - GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        \n",
    "        super(Model_GRU, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        #activation function\n",
    "#         self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, x_length):\n",
    "   \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "\n",
    "        out = out[torch.arange(batch_size),x_length,:].reshape(1,batch_size,self.hidden_dim)\n",
    "        dense_outputs=self.fc(out)\n",
    "        \n",
    "\n",
    "        output = self.softmax(dense_outputs)\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    for x_input, y_label, x_length in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        output= model(x_input, x_length).squeeze()\n",
    "  \n",
    "        #compute the loss\n",
    "        loss = criterion(output, y_label.long())        \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "#         acc = binary_accuracy(output, batch.label)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()     \n",
    "        \n",
    "        #clip gradient, to prevent from exploding\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "#         epoch_acc += acc.item()    \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "# , epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_GRU(input_size=300, output_size=3, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_rnn_ternary, y_train_rnn_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.895\n",
      "\tTrain Loss: 0.751\n",
      "\tTrain Loss: 0.711\n",
      "\tTrain Loss: 0.690\n",
      "\tTrain Loss: 0.677\n",
      "\tTrain Loss: 0.667\n",
      "\tTrain Loss: 0.658\n",
      "\tTrain Loss: 0.651\n",
      "\tTrain Loss: 0.645\n",
      "\tTrain Loss: 0.639\n",
      "\tTrain Loss: 0.634\n",
      "\tTrain Loss: 0.630\n",
      "\tTrain Loss: 0.626\n",
      "\tTrain Loss: 0.622\n",
      "\tTrain Loss: 0.618\n",
      "\tTrain Loss: 0.614\n",
      "\tTrain Loss: 0.611\n",
      "\tTrain Loss: 0.608\n",
      "\tTrain Loss: 0.605\n",
      "\tTrain Loss: 0.602\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=myDataset(X_test_rnn_ternary, y_test_rnn_ternary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.74      0.78     21579\n",
      "         1.0       0.82      0.78      0.80     21304\n",
      "         2.0       0.32      0.45      0.37      7061\n",
      "\n",
      "    accuracy                           0.72     49944\n",
      "   macro avg       0.65      0.66      0.65     49944\n",
      "weighted avg       0.75      0.72      0.73     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=prebuiltDataset(X_train_rnn_ternary, y_train_rnn_ternary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_GRU(input_size=300, output_size=3, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.895\n",
      "Epoch: 1\tTrain Loss: 0.794\n",
      "Epoch: 2\tTrain Loss: 0.744\n",
      "Epoch: 3\tTrain Loss: 0.724\n",
      "Epoch: 4\tTrain Loss: 0.711\n",
      "Epoch: 5\tTrain Loss: 0.700\n",
      "Epoch: 6\tTrain Loss: 0.691\n",
      "Epoch: 7\tTrain Loss: 0.684\n",
      "Epoch: 8\tTrain Loss: 0.678\n",
      "Epoch: 9\tTrain Loss: 0.673\n",
      "Epoch: 10\tTrain Loss: 0.669\n",
      "Epoch: 11\tTrain Loss: 0.665\n",
      "Epoch: 12\tTrain Loss: 0.661\n",
      "Epoch: 13\tTrain Loss: 0.657\n",
      "Epoch: 14\tTrain Loss: 0.655\n",
      "Epoch: 15\tTrain Loss: 0.652\n",
      "Epoch: 16\tTrain Loss: 0.649\n",
      "Epoch: 17\tTrain Loss: 0.647\n",
      "Epoch: 18\tTrain Loss: 0.645\n",
      "Epoch: 19\tTrain Loss: 0.643\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=prebuiltDataset(X_test_rnn_ternary, y_test_rnn_ternary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.72      0.78     22858\n",
      "         1.0       0.81      0.79      0.80     20765\n",
      "         2.0       0.29      0.45      0.35      6321\n",
      "\n",
      "    accuracy                           0.72     49944\n",
      "   macro avg       0.64      0.66      0.64     49944\n",
      "weighted avg       0.76      0.72      0.73     49944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=myDataset(X_train_rnn_binary, y_train_rnn_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_GRU(input_size=300, output_size=2, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.470\n",
      "Epoch: 1\tTrain Loss: 0.354\n",
      "Epoch: 2\tTrain Loss: 0.330\n",
      "Epoch: 3\tTrain Loss: 0.316\n",
      "Epoch: 4\tTrain Loss: 0.303\n",
      "Epoch: 5\tTrain Loss: 0.294\n",
      "Epoch: 6\tTrain Loss: 0.286\n",
      "Epoch: 7\tTrain Loss: 0.280\n",
      "Epoch: 8\tTrain Loss: 0.274\n",
      "Epoch: 9\tTrain Loss: 0.268\n",
      "Epoch: 10\tTrain Loss: 0.264\n",
      "Epoch: 11\tTrain Loss: 0.259\n",
      "Epoch: 12\tTrain Loss: 0.255\n",
      "Epoch: 13\tTrain Loss: 0.250\n",
      "Epoch: 14\tTrain Loss: 0.247\n",
      "Epoch: 15\tTrain Loss: 0.243\n",
      "Epoch: 16\tTrain Loss: 0.240\n",
      "Epoch: 17\tTrain Loss: 0.237\n",
      "Epoch: 18\tTrain Loss: 0.234\n",
      "Epoch: 19\tTrain Loss: 0.231\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=myDataset(X_test_rnn_binary, y_test_rnn_binary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88     19864\n",
      "         1.0       0.88      0.88      0.88     20091\n",
      "\n",
      "    accuracy                           0.88     39955\n",
      "   macro avg       0.88      0.88      0.88     39955\n",
      "weighted avg       0.88      0.88      0.88     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model - Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=prebuiltDataset(X_train_rnn_binary, y_train_rnn_binary)\n",
    "training_generator = data.DataLoader(training_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model_GRU(input_size=300, output_size=2, hidden_dim=50, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "# n_epochs = 2\n",
    "lr=0.0001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain Loss: 0.458\n",
      "Epoch: 1\tTrain Loss: 0.387\n",
      "Epoch: 2\tTrain Loss: 0.361\n",
      "Epoch: 3\tTrain Loss: 0.343\n",
      "Epoch: 4\tTrain Loss: 0.331\n",
      "Epoch: 5\tTrain Loss: 0.321\n",
      "Epoch: 6\tTrain Loss: 0.314\n",
      "Epoch: 7\tTrain Loss: 0.307\n",
      "Epoch: 8\tTrain Loss: 0.303\n",
      "Epoch: 9\tTrain Loss: 0.299\n",
      "Epoch: 10\tTrain Loss: 0.295\n",
      "Epoch: 11\tTrain Loss: 0.291\n",
      "Epoch: 12\tTrain Loss: 0.288\n",
      "Epoch: 13\tTrain Loss: 0.285\n",
      "Epoch: 14\tTrain Loss: 0.282\n",
      "Epoch: 15\tTrain Loss: 0.280\n",
      "Epoch: 16\tTrain Loss: 0.277\n",
      "Epoch: 17\tTrain Loss: 0.275\n",
      "Epoch: 18\tTrain Loss: 0.273\n",
      "Epoch: 19\tTrain Loss: 0.271\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "#     train_loss, train_acc = train(model, training_generator, optimizer, criterion)\n",
    "    train_loss= train(model, training_generator, optimizer, criterion)\n",
    "    \n",
    "#     #evaluate the model\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     #save the best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch}\\tTrain Loss: {train_loss:.3f}') \n",
    "#           | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=prebuiltDataset(X_test_rnn_binary, y_test_rnn_binary)\n",
    "testing_generator = data.DataLoader(testing_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_batch in testing_generator:\n",
    "    pred=model(test_batch[0], test_batch[2]).squeeze().topk(1)[1].T[0].numpy()\n",
    "    y_pred=np.append(y_pred,pred)\n",
    "    y_true=np.append(y_true,test_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.88     19581\n",
      "         1.0       0.89      0.87      0.88     20374\n",
      "\n",
      "    accuracy                           0.88     39955\n",
      "   macro avg       0.88      0.88      0.88     39955\n",
      "weighted avg       0.88      0.88      0.88     39955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_bin=classification_report(y_pred, y_true, output_dict=True)\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Accuracies - Binary:\n",
    "\n",
    "### Simple Model (task 3)- \n",
    "\n",
    "#### SVM\n",
    "Tf-Idf - 0.87\n",
    "\n",
    "My Model - 0.84\n",
    "\n",
    "Prebuilt Model - 0.82 \n",
    "\n",
    "#### Perceptron\n",
    "Tf-Idf - 0.83\n",
    "\n",
    "My Model - 0.79\n",
    "\n",
    "Prebuilt Model - 0.71\n",
    "\n",
    "### Feed-Forward Neural Network (task 4)\n",
    "\n",
    "#### Input Type 1 (task 4A)\n",
    "My Model - 0.84\n",
    "\n",
    "Prebuilt Model - 0.76\n",
    "\n",
    "#### Input Type 2 (task 4B)\n",
    "My Model - 0.78\n",
    "\n",
    "Prebuilt Model - 0.76\n",
    "\n",
    "### RNN (task 5A)-\n",
    "My Model - 0.85\n",
    "\n",
    "Prebuilt Model - 0.86\n",
    "\n",
    "### GRU (task 5B)-\n",
    "My Model - 0.88\n",
    "\n",
    "Prebuilt Model - 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Accuracies - Ternary:\n",
    "\n",
    "### Feed-Forward Neural Network (task 4)\n",
    "\n",
    "#### Input Type 1 (task 4A)\n",
    "My Model - 0.69\n",
    "\n",
    "Prebuilt Model - 0.67\n",
    "\n",
    "#### Input Type 2 (task 4B)\n",
    "My Model - 0.63\n",
    "\n",
    "Prebuilt Model - 0.62\n",
    "\n",
    "### RNN (task 5A)-\n",
    "My Model - 0.69\n",
    "\n",
    "Prebuilt Model - 0.69\n",
    "\n",
    "### GRU (task 5B)-\n",
    "My Model - 0.72\n",
    "\n",
    "Prebuilt Model - 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be concluded that TF-IDF feature type works the best. Among the rest of the two, the model which we made works better than the prebuilt model. This is mainly because our model is generated from the dataset which is used in this testing while the prebuilt model is more generic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM performed best for binary classification task. But Feed-Forward Neural Network with same word embeddings input as SVM also gave promising results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN and GRU gave promising results for Binary Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies were consistently low for ternary classification. This is due to the class imbalance as class 2 was only half as compared to class 0 or 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there would have been more computational resources, the grid-search could be applied to find out better hyperparamters and give better result. But due to less RAM and Memory, my laptop was crashing again and again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
