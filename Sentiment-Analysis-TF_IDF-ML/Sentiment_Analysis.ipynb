{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Amazon Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Sentiment Analysis\n",
    "## Data Cleaning -> Data Preprocessing -> TF-IDF -> ML Algorithms (Perceptron, SVM, Logistic Regression, Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " data=pd.read_csv('amazon_reviews_us_Kitchen_v1_00.tsv', sep=\"\\t\", error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[[\"review_body\",\"star_rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>426870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>241939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>349539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>731701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>3124595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1.0               426870\n",
       "2.0               241939\n",
       "3.0               349539\n",
       "4.0               731701\n",
       "5.0              3124595"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of all the reviews\n",
    "df=df.dropna()\n",
    "df_grouped = df.groupby('star_rating')\n",
    "df_grouped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of reviews having rating less than 3:  668809\n",
      "Count of reviews having rating  3:  349539\n",
      "Count of reviews having rating more than 3:  3856296\n"
     ]
    }
   ],
   "source": [
    "#statistics of the 3 classes\n",
    "count_3 = df_grouped.get_group(3.0).count()[1]\n",
    "count_less = df_grouped.get_group(1.0).count()[1] + df_grouped.get_group(2.0).count()[1]\n",
    "count_more = df_grouped.get_group(4.0).count()[1] + df_grouped.get_group(5.0).count()[1]\n",
    "counts=count_more, count_less, count_3\n",
    "print(\"Count of reviews having rating less than 3: \",count_less)\n",
    "print(\"Count of reviews having rating  3: \",count_3)\n",
    "print(\"Count of reviews having rating more than 3: \",count_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled=df.copy()\n",
    "df_labeled=df_labeled[df_labeled[\"star_rating\"]!=3.0]\n",
    "df_labeled[\"star_rating\"]=(df_labeled[\"star_rating\"]>3)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1252980</th>\n",
       "      <td>Awesome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370796</th>\n",
       "      <td>I use this everytime I cook....  handy tool.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813246</th>\n",
       "      <td>2 1/2 weeks into juicing as a lifestyle change...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672884</th>\n",
       "      <td>Very happy with Kitchen Aid Convection Oven. K...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076561</th>\n",
       "      <td>This can opener will make you curse the day yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "1252980                                            Awesome            1\n",
       "2370796       I use this everytime I cook....  handy tool.            1\n",
       "2813246  2 1/2 weeks into juicing as a lifestyle change...            0\n",
       "1672884  Very happy with Kitchen Aid Convection Oven. K...            1\n",
       "4076561  This can opener will make you curse the day yo...            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3856296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "0                 668809\n",
       "1                3856296"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics of just the 2 classes used\n",
    "df_labeled.groupby('star_rating').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance \n",
    "### We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=df_labeled[df_labeled[\"star_rating\"]==0].sample(100000, replace=False)\n",
    "df_1=df_labeled[df_labeled[\"star_rating\"]==1].sample(100000, replace=False)\n",
    "df_subset=pd.concat([df_0,df_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## average character length before cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322.26184\n"
     ]
    }
   ],
   "source": [
    "char_len_before = sum(list(df_subset[\"review_body\"].str.len()))/df_subset.shape[0]\n",
    "print(char_len_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## sample reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3710130</th>\n",
       "      <td>Basically, it is a nice unit and works well as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669251</th>\n",
       "      <td>Returning because the &amp;#34;bagel&amp;#34; function...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788646</th>\n",
       "      <td>Coffee presses work pretty much the same way. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656991</th>\n",
       "      <td>I just purchased this pan after having impress...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489238</th>\n",
       "      <td>Pretty chrome, spins easily, holds all the k c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "3710130  Basically, it is a nice unit and works well as...            0\n",
       "669251   Returning because the &#34;bagel&#34; function...            0\n",
       "4788646  Coffee presses work pretty much the same way. ...            1\n",
       "3656991  I just purchased this pan after having impress...            1\n",
       "3489238  Pretty chrome, spins easily, holds all the k c...            1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['review_body']=df_subset['review_body'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    text=str(text)\n",
    "    text = re.sub(clean, '', text)\n",
    "    return re.sub(r\"\\S*http\\S+\", \"\", text)\n",
    "\n",
    "df_subset['review_body']=df_subset['review_body'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "def contractionfunction(s):\n",
    "    s=contractions.fix(s)\n",
    "    return s\n",
    "df_subset['review_body']=df_subset['review_body'].apply(contractionfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha(text):\n",
    "    clean = re.compile('[^a-zA-Z]+')\n",
    "    text=str(text)\n",
    "    return re.sub(clean, ' ', text)\n",
    "\n",
    "df_subset['review_body']=df_subset['review_body'].apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(text):\n",
    "     return re.sub(' +', ' ', str(text.strip()))\n",
    "\n",
    "df_subset['review_body']=df_subset['review_body'].apply(remove_extra_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## average character length after cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308.18849\n"
     ]
    }
   ],
   "source": [
    "char_len_after = sum(df_subset[\"review_body\"].str.len())/df_subset.shape[0]\n",
    "print(char_len_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words(\"english\"))                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_remove_stopwords(text):\n",
    "    text = ' '.join([wnl.lemmatize(word) for word in nltk.word_tokenize(text) if  word not in stopwords_set])\n",
    "    return text\n",
    "\n",
    "df_subset['review_body']=df_subset['review_body'].apply(lemmatize_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## average character length after preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.97449\n"
     ]
    }
   ],
   "source": [
    "char_len_after_prep = sum(df_subset[\"review_body\"].str.len())/df_subset.shape[0]\n",
    "char_len_clean=char_len_before, char_len_after\n",
    "char_len_prep=char_len_after, char_len_after_prep\n",
    "print(char_len_after_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## sample review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2982855</th>\n",
       "      <td>shattered bumped side wooden table glass thin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942189</th>\n",
       "      <td>wife received set quickly corrosion far moth u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791931</th>\n",
       "      <td>perfect fridge check meat temp requirement rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494843</th>\n",
       "      <td>le day bought turned yesterday flash burst sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969468</th>\n",
       "      <td>fionally uused first time filled water coffee ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "2982855  shattered bumped side wooden table glass thin ...            0\n",
       "3942189  wife received set quickly corrosion far moth u...            1\n",
       "1791931  perfect fridge check meat temp requirement rea...            1\n",
       "3494843  le day bought turned yesterday flash burst sou...            0\n",
       "1969468  fionally uused first time filled water coffee ...            0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  train-test split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_subset[\"review_body\"], df_subset[\"star_rating\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf= vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_train_pred=clf.predict(X_train_tfidf)\n",
    "y_test_pred=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Perceptron----------\n",
      "TRAIN Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     80007\n",
      "           1       0.91      0.91      0.91     79993\n",
      "\n",
      "    accuracy                           0.91    160000\n",
      "   macro avg       0.91      0.91      0.91    160000\n",
      "weighted avg       0.91      0.91      0.91    160000\n",
      "\n",
      "\n",
      "TEST Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86     19993\n",
      "           1       0.86      0.86      0.86     20007\n",
      "\n",
      "    accuracy                           0.86     40000\n",
      "   macro avg       0.86      0.86      0.86     40000\n",
      "weighted avg       0.86      0.86      0.86     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_train=classification_report(y_train, y_train_pred, output_dict=True)\n",
    "cl_report_train_string=classification_report(y_train, y_train_pred)\n",
    "print(\"----------Perceptron----------\")\n",
    "print(\"TRAIN Classification Report\")\n",
    "print(cl_report_train_string)\n",
    "cl_report_test=classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cl_report_test_string=classification_report(y_test, y_test_pred)\n",
    "print(\"\\nTEST Classification Report\")\n",
    "print(cl_report_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_train=cl_report_train[\"accuracy\"], cl_report_train[\"macro avg\"][\"precision\"], cl_report_train[\"macro avg\"][\"recall\"], cl_report_train[\"macro avg\"][\"f1-score\"]\n",
    "perceptron_test=cl_report_test[\"accuracy\"], cl_report_test[\"macro avg\"][\"precision\"], cl_report_test[\"macro avg\"][\"recall\"], cl_report_test[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_train_pred=clf.predict(X_train_tfidf)\n",
    "y_test_pred=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------SVM----------\n",
      "TRAIN Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     80007\n",
      "           1       0.93      0.93      0.93     79993\n",
      "\n",
      "    accuracy                           0.93    160000\n",
      "   macro avg       0.93      0.93      0.93    160000\n",
      "weighted avg       0.93      0.93      0.93    160000\n",
      "\n",
      "\n",
      "TEST Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     19993\n",
      "           1       0.90      0.90      0.90     20007\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.90      0.90      0.90     40000\n",
      "weighted avg       0.90      0.90      0.90     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_train=classification_report(y_train, y_train_pred, output_dict=True)\n",
    "cl_report_train_string=classification_report(y_train, y_train_pred)\n",
    "print(\"----------SVM----------\")\n",
    "print(\"TRAIN Classification Report\")\n",
    "print(cl_report_train_string)\n",
    "cl_report_test=classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cl_report_test_string=classification_report(y_test, y_test_pred)\n",
    "print(\"\\nTEST Classification Report\")\n",
    "print(cl_report_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train=cl_report_train[\"accuracy\"], cl_report_train[\"macro avg\"][\"precision\"], cl_report_train[\"macro avg\"][\"recall\"], cl_report_train[\"macro avg\"][\"f1-score\"]\n",
    "svm_test=cl_report_test[\"accuracy\"], cl_report_test[\"macro avg\"][\"precision\"], cl_report_test[\"macro avg\"][\"recall\"], cl_report_test[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=250)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_train_pred=clf.predict(X_train_tfidf)\n",
    "y_test_pred=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Logistic Regression----------\n",
      "TRAIN Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91     80007\n",
      "           1       0.92      0.91      0.91     79993\n",
      "\n",
      "    accuracy                           0.91    160000\n",
      "   macro avg       0.91      0.91      0.91    160000\n",
      "weighted avg       0.91      0.91      0.91    160000\n",
      "\n",
      "\n",
      "TEST Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     19993\n",
      "           1       0.90      0.90      0.90     20007\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.90      0.90      0.90     40000\n",
      "weighted avg       0.90      0.90      0.90     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_train=classification_report(y_train, y_train_pred, output_dict=True)\n",
    "cl_report_train_string=classification_report(y_train, y_train_pred)\n",
    "print(\"----------Logistic Regression----------\")\n",
    "print(\"TRAIN Classification Report\")\n",
    "print(cl_report_train_string)\n",
    "cl_report_test=classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cl_report_test_string=classification_report(y_test, y_test_pred)\n",
    "print(\"\\nTEST Classification Report\")\n",
    "print(cl_report_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train=cl_report_train[\"accuracy\"], cl_report_train[\"macro avg\"][\"precision\"], cl_report_train[\"macro avg\"][\"recall\"], cl_report_train[\"macro avg\"][\"f1-score\"]\n",
    "lr_test=cl_report_test[\"accuracy\"], cl_report_test[\"macro avg\"][\"precision\"], cl_report_test[\"macro avg\"][\"recall\"], cl_report_test[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_train_pred=clf.predict(X_train_tfidf)\n",
    "y_test_pred=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Naive Bayes----------\n",
      "TRAIN Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89     80007\n",
      "           1       0.89      0.88      0.88     79993\n",
      "\n",
      "    accuracy                           0.88    160000\n",
      "   macro avg       0.88      0.88      0.88    160000\n",
      "weighted avg       0.88      0.88      0.88    160000\n",
      "\n",
      "\n",
      "TEST Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87     19993\n",
      "           1       0.88      0.87      0.87     20007\n",
      "\n",
      "    accuracy                           0.87     40000\n",
      "   macro avg       0.87      0.87      0.87     40000\n",
      "weighted avg       0.87      0.87      0.87     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cl_report_train=classification_report(y_train, y_train_pred, output_dict=True)\n",
    "cl_report_train_string=classification_report(y_train, y_train_pred)\n",
    "print(\"----------Naive Bayes----------\")\n",
    "print(\"TRAIN Classification Report\")\n",
    "print(cl_report_train_string)\n",
    "cl_report_test=classification_report(y_test, y_test_pred, output_dict=True)\n",
    "cl_report_test_string=classification_report(y_test, y_test_pred)\n",
    "print(\"\\nTEST Classification Report\")\n",
    "print(cl_report_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train=cl_report_train[\"accuracy\"], cl_report_train[\"macro avg\"][\"precision\"], cl_report_train[\"macro avg\"][\"recall\"], cl_report_train[\"macro avg\"][\"f1-score\"]\n",
    "nb_test=cl_report_test[\"accuracy\"], cl_report_test[\"macro avg\"][\"precision\"], cl_report_test[\"macro avg\"][\"recall\"], cl_report_test[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It can be observed that the SVM model performs the best with an accuracy of 93% on Train and 90% on test. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
