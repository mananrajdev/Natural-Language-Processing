{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dae114",
   "metadata": {},
   "source": [
    "# MANAN RAJDEV - CSCI 544 - HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056b54d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0eea2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa53bc",
   "metadata": {},
   "source": [
    "## Task 1 - Vocabulary Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a09d691",
   "metadata": {},
   "source": [
    "Data Preprocessing -> converted all number tags to a token (<num>) and words with a low frequency to a special token (<unk>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fad1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"data/train\", sep=\"\\t\", names=[\"idx\",\"word\",\"tag\"])\n",
    "# df_train['word']=df_train['word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b863db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev=pd.read_csv(\"data/dev\", sep=\"\\t\", names=[\"idx\",\"word\",\"tag\"])\n",
    "# df_dev[\"word\"]=df_dev['word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3075d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"data/test\", sep=\"\\t\", names=[\"idx\",\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6fb62511",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = \"< unk >\"\n",
    "unk_num_token = \"< num >\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad963af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['word'] = df_train['word'].str.replace(r'^(\\d*\\.?\\d+|\\d{1,3}(,\\d{3})*(\\.\\d+)?)$',unk_num_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a5db3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_dev['word'] = df_dev['word'].str.replace(r'^(\\d*\\.?\\d+|\\d{1,3}(,\\d{3})*(\\.\\d+)?)$',unk_num_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a6baec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['word'] = df_test['word'].str.replace(r'^(\\d*\\.?\\d+|\\d{1,3}(,\\d{3})*(\\.\\d+)?)$',unk_num_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0867d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unk\n",
    "threshold=2\n",
    "df_vocab=pd.DataFrame(df_train['word'].value_counts())\n",
    "v_size=df_vocab.shape[0]\n",
    "unk=sum(df_vocab['word'][df_vocab['word']<threshold])\n",
    "df_vocab=df_vocab[df_vocab['word']>=threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c291c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e2d1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab.loc[-1]=[unk_token,unk]\n",
    "df_vocab.index+=1\n",
    "df_vocab.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33f95c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab.reset_index(inplace=True)\n",
    "df_vocab.rename(columns={\"word\":\"frequency\",\"index\":\"word\",\"level_0\":\"index\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "816a9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab=df_vocab[[\"word\",\"index\",\"frequency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9dea429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab.to_csv(\"vocab.txt\",sep=\"\\t\", header=False, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd67ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What is the selected threshold for unknown words replacement? \n",
      "Ans. 2\n",
      "\n",
      "What is the total size of your vocabulary?\n",
      "Ans. 38917\n",
      "\n",
      "What is the total occurrences of the special token '< unk >' after replacement?\n",
      "Ans. 17347\n",
      "\n",
      "What is the final size of your vocabulary?\n",
      "Ans. 21571\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "What is the selected threshold for unknown words replacement? \n",
    "Ans. {threshold}\n",
    "\n",
    "What is the total size of your vocabulary?\n",
    "Ans. {v_size}\n",
    "\n",
    "What is the total occurrences of the special token '< unk >' after replacement?\n",
    "Ans. {unk}\n",
    "\n",
    "What is the final size of your vocabulary?\n",
    "Ans. {df_vocab.shape[0]}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13ce5afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>17347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt; num &gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>22869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  index  frequency\n",
       "0  < unk >      0      17347\n",
       "1        ,      1      46476\n",
       "2      the      2      39533\n",
       "3        .      3      37452\n",
       "4  < num >      4      22869"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031d229",
   "metadata": {},
   "source": [
    "## Task 2 - Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f2ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_s=df_train[\"tag\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a89bc3",
   "metadata": {},
   "source": [
    "### Emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a709632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['normalized']=df_train['word'].where(df_train['word'].isin(df_vocab['word']).astype(int)==1, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f947985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s->x\"]=list(zip(df_train[\"tag\"],df_train[\"normalized\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cab1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_em=df_train[\"s->x\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2deb5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df_train.drop_duplicates(subset=[\"s->x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a12fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission={}\n",
    "for i in range(df_temp.shape[0]):\n",
    "    em=df_temp.iloc[i,-1]\n",
    "\n",
    "    s=df_temp.iloc[i,2]\n",
    "\n",
    "    emission[em]=count_em[em]/count_s[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ee41661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission Parameters:  28681\n"
     ]
    }
   ],
   "source": [
    "print(\"Emission Parameters: \",len(emission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdb0522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_dict = df_train.groupby('normalized')['tag'].apply(set).apply(list).to_dict()\n",
    "# set(a.get_group(unk_token)['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e0497",
   "metadata": {},
   "source": [
    "### Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca9692ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"s->x\",\"normalized\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b64ddc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=list(df_train[\"tag\"][:-1])\n",
    "temp=[\".\"]+temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "189cb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s_dash\"]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6a8453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s->s_dash\"]=list(zip(df_train[\"s_dash\"],df_train[\"tag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01e60f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tn=df_train[\"s->s_dash\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6d8469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df_train.drop_duplicates(subset=[\"s->s_dash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12807a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition={}\n",
    "for i in range(df_temp.shape[0]):\n",
    "    tn=df_temp.iloc[i,-1]\n",
    "    s=df_temp.iloc[i,-2]\n",
    "    transition[tn]=count_tn[tn]/count_s[s]\n",
    "#     transition[tuple(tn.split(\"###\"))]=count_tn[tn]/count_s[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "118c508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Parameters:  1378\n"
     ]
    }
   ],
   "source": [
    "print(\"Transition Parameters: \",len(transition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228839e",
   "metadata": {},
   "source": [
    "### Storing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48600968",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_values = emission.items()\n",
    "new_emission = {str(key): value for key, value in keys_values}\n",
    "keys_values = transition.items()\n",
    "new_transition= {str(key): value for key, value in keys_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60cb93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result={}\n",
    "result['emission']=new_emission\n",
    "result['transition']=new_transition\n",
    "f = open(\"hmm.json\", mode = 'w', encoding = 'UTF-8')\n",
    "f.write(json.dumps(result))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9414c",
   "metadata": {},
   "source": [
    "## Task 3 - Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "650d7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag=list(count_s.keys())\n",
    "valid_words=set(df_vocab['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53e269de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(words, train_bag = train_bag, valid_words=valid_words):\n",
    "    state = []\n",
    "    T = train_bag\n",
    "    W=valid_words\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        word = word if word in W else unk_token\n",
    "        p = [] \n",
    "        for tag in word_tag_dict[word]:\n",
    "            if key == 0:\n",
    "                transition_p = transition.get(('.',tag),0)\n",
    "            else:\n",
    "                transition_p = transition.get((state[-1],tag),0)\n",
    "                 \n",
    "\n",
    "            \n",
    "            emission_p = emission.get((tag,word),0)\n",
    "           \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "\n",
    "        state_max = word_tag_dict[word][p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "#     return list(zip(words, state))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac259aa",
   "metadata": {},
   "source": [
    "### Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ced7080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['y_pred']=greedy(list(df_dev['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1152614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"bool\"]=df_dev['tag']==df_dev['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22953b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Greedy Approach:  93.74127253961508\n"
     ]
    }
   ],
   "source": [
    "accuracy_greedy=sum(df_dev[\"bool\"])/len(df_dev)\n",
    "print(\"Accuracy of Greedy Approach: \",accuracy_greedy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dac985bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop([\"y_pred\",\"bool\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f2690",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d31c100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new=pd.read_csv(\"data/test\", sep=\"\\t\", names=[\"idx\",\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "060ef605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['y_pred']=greedy(list(df_test['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "376ac3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['tag']=df_test['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aace7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"greedy.out\", 'w').close()\n",
    "f = open(\"greedy.out\", \"a\")\n",
    "for i in range(len(df_test_new)):\n",
    "    f.write(f'{df_test_new.iloc[i,0]}\\t{df_test_new.iloc[i,1]}\\t{df_test_new.iloc[i,2]}\\n')\n",
    "    if df_test_new.iloc[i,1]==\".\":\n",
    "        pass\n",
    "    elif df_test_new.iloc[i+1,0]==1:\n",
    "        f.write(\"\\n\")\n",
    "    else:\n",
    "        pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0349d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(\"y_pred\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2889f",
   "metadata": {},
   "source": [
    "## Task 4 - Viterbi Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8798ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words):\n",
    "    \n",
    "    result_dict = {}  # 3d - matrix to store the data..\n",
    "    for i in range(0, len(words) + 1):\n",
    "        result_dict[i] = {}\n",
    "        if i == len(words):\n",
    "            maxValue = -float(\"inf\")\n",
    "            result = ''\n",
    "            for previousTag in result_dict[i - 1].keys():\n",
    "                probablity = result_dict[i - 1][previousTag]['probablity'] *  transition.get((previousTag,'.'),0)\n",
    "                if probablity > maxValue:\n",
    "                    maxValue = probablity\n",
    "                    result = previousTag\n",
    "            result_dict[i]['end'] = {}\n",
    "            result_dict[i]['end']['probablity'] = maxValue\n",
    "            result_dict[i]['end']['backpointer'] = result\n",
    "            continue\n",
    "        \n",
    "        word = words[i]\n",
    "        word = word if word in valid_words else unk_token\n",
    "        \n",
    "        if i == 0:\n",
    "            for tag in word_tag_dict[word]:\n",
    "                result_dict[i][tag] = {}\n",
    "                result_dict[i][tag]['probablity'] = emission.get((tag,word),0) * transition.get(('.',tag),0)\n",
    "                result_dict[i][tag]['backpointer'] = 'start'\n",
    " \n",
    "            continue\n",
    "\n",
    "       \n",
    "        for tag in word_tag_dict[word]:\n",
    "            result_dict[i][tag] = {}\n",
    "            maxValue = -float(\"inf\")\n",
    "            result = ''\n",
    "            for previousTag in result_dict[i - 1].keys():\n",
    "                probablity = result_dict[i - 1][previousTag]['probablity'] * emission.get((tag,word),0) * transition.get((previousTag,tag),0)\n",
    "                if probablity > maxValue:\n",
    "                    maxValue = probablity\n",
    "                    result = previousTag\n",
    "            result_dict[i][tag] = {}\n",
    "            result_dict[i][tag]['probablity'] = maxValue\n",
    "            result_dict[i][tag]['backpointer'] = result\n",
    "\n",
    "    \n",
    "\n",
    "    tag_sentence_list = []\n",
    "    startTag = 'end'\n",
    "    i = len(result_dict) - 1;\n",
    "    j = len(result_dict) - 2;\n",
    "    while i - 1 >= 0:\n",
    "        tag = result_dict[i][startTag]['backpointer']\n",
    "        tag_sentence_list.append(tag)\n",
    "        startTag = tag\n",
    "        i = i - 1\n",
    "        j = j - 1\n",
    "    return tag_sentence_list[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec7215",
   "metadata": {},
   "source": [
    "### Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2bcdaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "sentences=[]\n",
    "y_pred=[]\n",
    "for i in range(len(df_dev)):\n",
    "    temp.append(df_dev.iloc[i,1])\n",
    "    if df_dev.iloc[i,1]==\".\":\n",
    "        if i==len(df_dev)-1:\n",
    "            y_pred+=Viterbi(temp)\n",
    "            temp=[]\n",
    "        elif df_dev.iloc[i+1,0]==1:\n",
    "            y_pred+=Viterbi(temp)\n",
    "            temp=[]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e652c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['y_pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0dc62055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['bool']=df_dev['tag']==df_dev['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f0b06c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Viterbi Approach:  94.96008135510898\n"
     ]
    }
   ],
   "source": [
    "accuracy_viterbi=sum(df_dev[\"bool\"])/len(df_dev)\n",
    "print(\"Accuracy of Viterbi Approach: \",accuracy_viterbi*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7daf20f",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "891bb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "sentences=[]\n",
    "y_pred=[]\n",
    "for i in range(len(df_test)):\n",
    "    temp.append(df_test.iloc[i,1])\n",
    "    if df_test.iloc[i,1]==\".\":\n",
    "        if i==len(df_test)-1:\n",
    "            y_pred+=Viterbi(temp)\n",
    "            temp=[]\n",
    "        elif df_test.iloc[i+1,0]==1:\n",
    "            y_pred+=Viterbi(temp)\n",
    "            temp=[]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1ca42c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['tag']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b1efcb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"viterbi.out\", 'w').close()\n",
    "f = open(\"viterbi.out\", \"a\")\n",
    "for i in range(len(df_test_new)):\n",
    "    f.write(f'{df_test_new.iloc[i,0]}\\t{df_test_new.iloc[i,1]}\\t{df_test_new.iloc[i,2]}\\n')\n",
    "    if df_test_new.iloc[i,1]==\".\":\n",
    "        pass\n",
    "    elif df_test_new.iloc[i+1,0]==1:\n",
    "        f.write(\"\\n\")\n",
    "    else:\n",
    "        pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b76f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bda30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
